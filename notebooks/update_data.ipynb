{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6f5aacab-9a44-4a16-b315-458fe0382a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd, requests\n",
    "\n",
    "ROOT = Path().resolve()\n",
    "DATA_RAW  = ROOT.parent / \"data\" / \"raw\"\n",
    "DATA_PROC = ROOT.parent / \"data\" / \"processed\"\n",
    "DATA_RAW.mkdir(parents=True, exist_ok=True)\n",
    "DATA_PROC.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "33e7029c-2ea3-46c9-b623-5a838df0cf44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lfsa_ehomp → guardado en C:\\Users\\mdmg9\\OneDrive\\Vac UE\\Sep25\\eu-lfs-telework-2015-2024\\data\\raw\\lfsa_ehomp.csv\n",
      "lfso_21jsat04 → guardado en C:\\Users\\mdmg9\\OneDrive\\Vac UE\\Sep25\\eu-lfs-telework-2015-2024\\data\\raw\\lfso_21jsat04.csv\n",
      "lfso_21jsat01 → guardado en C:\\Users\\mdmg9\\OneDrive\\Vac UE\\Sep25\\eu-lfs-telework-2015-2024\\data\\raw\\lfso_21jsat01.csv\n"
     ]
    }
   ],
   "source": [
    "#descarga\n",
    "\n",
    "BASE = \"https://ec.europa.eu/eurostat/api/dissemination/sdmx/2.1/data\"\n",
    "\n",
    "DATASETS = {\n",
    "    # Código (Eurostat) : alias\n",
    "    \"lfsa_ehomp\":    \"telework\",          # Teletrabajo (% empleo)\n",
    "    \"lfso_21jsat04\": \"jobsat_wfh_flex\",   # Job satisfaction × WFH × flexibilidad\n",
    "    \"lfso_21jsat01\": \"jobsat_baseline\",   # Job satisfaction (baseline)\n",
    "}\n",
    "\n",
    "def eurostat_url(dataset: str, fmt=\"SDMX-CSV\"):\n",
    "    # Filtramos años 2015..2024 para limitar tamaño de respuesta\n",
    "    return (\n",
    "        f\"{BASE}/{dataset}\"\n",
    "        f\"?time=2015:2024\"\n",
    "        f\"&format={fmt}\"\n",
    "        f\"&compressed=false\"\n",
    "        f\"&lang=en\"\n",
    "    )\n",
    "\n",
    "def download_dataset(dataset: str):\n",
    "    # 1º intento: SDMX-CSV\n",
    "    url_csv = eurostat_url(dataset, fmt=\"SDMX-CSV\")\n",
    "    r = requests.get(url_csv, timeout=120)\n",
    "    if r.ok and r.content.strip():\n",
    "        out = DATA_RAW / f\"{dataset}.csv\"\n",
    "        out.write_bytes(r.content)\n",
    "        return out\n",
    "\n",
    "    # Fallback: TSV\n",
    "    url_tsv = eurostat_url(dataset, fmt=\"TSV\")\n",
    "    r2 = requests.get(url_tsv, timeout=120)\n",
    "    r2.raise_for_status()\n",
    "    out = DATA_RAW / f\"{dataset}.tsv\"\n",
    "    out.write_bytes(r2.content)\n",
    "    return out\n",
    "\n",
    "raw_files = {}\n",
    "for code, _alias in DATASETS.items():\n",
    "    path = download_dataset(code)\n",
    "    raw_files[code] = path\n",
    "    print(code, \"→ guardado en\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "023eccba-df87-47e0-875a-a022376dc93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrado sex: 479727 -> 169075 filas (mantengo T/TOTAL)\n",
      "Filtrado age: escojo Y20-64  (169075 -> 7999 filas)\n",
      "Filtrado wstatus: escojo EMP  (7999 -> 1068 filas)\n",
      "Filtrado frequenc (USU/SMT): 1068 -> 712 filas\n",
      "Guardado: ..\\data\\processed\\lfsa_ehomp_2015_2024_clean.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>frequenc</th>\n",
       "      <th>geo</th>\n",
       "      <th>time</th>\n",
       "      <th>SMT</th>\n",
       "      <th>USU</th>\n",
       "      <th>telework_any</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT</td>\n",
       "      <td>2015</td>\n",
       "      <td>12.2</td>\n",
       "      <td>10.5</td>\n",
       "      <td>22.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT</td>\n",
       "      <td>2016</td>\n",
       "      <td>12.4</td>\n",
       "      <td>10.2</td>\n",
       "      <td>22.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT</td>\n",
       "      <td>2017</td>\n",
       "      <td>12.5</td>\n",
       "      <td>9.7</td>\n",
       "      <td>22.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT</td>\n",
       "      <td>2018</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>22.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT</td>\n",
       "      <td>2019</td>\n",
       "      <td>12.4</td>\n",
       "      <td>10.2</td>\n",
       "      <td>22.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "frequenc geo  time   SMT   USU  telework_any\n",
       "0         AT  2015  12.2  10.5          22.7\n",
       "1         AT  2016  12.4  10.2          22.6\n",
       "2         AT  2017  12.5   9.7          22.2\n",
       "3         AT  2018  12.0  10.2          22.2\n",
       "4         AT  2019  12.4  10.2          22.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#limpieza lfsa_ehomp.csv\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "RAW = Path(\"../data/raw/lfsa_ehomp.csv\")   # o .tsv\n",
    "OUT = Path(\"../data/processed/lfsa_ehomp_2015_2024_clean.csv\")\n",
    "\n",
    "df = pd.read_csv(RAW)\n",
    "df = df.rename(columns={\"TIME_PERIOD\":\"time\",\"OBS_VALUE\":\"value\"})\n",
    "df[\"value\"] = pd.to_numeric(df[\"value\"], errors=\"coerce\")\n",
    "\n",
    "# Años 2015–2024\n",
    "df = df[df[\"time\"].astype(str).str.fullmatch(r\"\\d{4}\")]\n",
    "df[\"time\"] = df[\"time\"].astype(int)\n",
    "df = df[df[\"time\"].between(2015, 2024)]\n",
    "df = df[df[\"value\"].notna()]\n",
    "\n",
    "# Normaliza EU28 -> EU27_2020 si aparece\n",
    "if \"geo\" in df.columns:\n",
    "    df[\"geo\"] = df[\"geo\"].replace({\"EU28\":\"EU27_2020\"})\n",
    "\n",
    "# --- Selección automática de \"totales\" ---\n",
    "\n",
    "# SEX: esperamos 'T'\n",
    "if \"sex\" in df.columns:\n",
    "    before = len(df)\n",
    "    df = df[df[\"sex\"].isin([\"T\",\"TOTAL\",\"All sexes\"])]\n",
    "    print(f\"Filtrado sex: {before} -> {len(df)} filas (mantengo T/TOTAL)\")\n",
    "\n",
    "# AGE: prioridad Y20-64 > Y15-64 > Y15-74 > TOTAL\n",
    "age_priority = [\"Y20-64\", \"Y15-64\", \"Y15-74\", \"TOTAL\", \"All ages\"]\n",
    "if \"age\" in df.columns:\n",
    "    available = [a for a in age_priority if a in set(df[\"age\"])]\n",
    "    if available:\n",
    "        pick = available[0]\n",
    "        before = len(df)\n",
    "        df = df[df[\"age\"] == pick]\n",
    "        print(f\"Filtrado age: escojo {pick}  ({before} -> {len(df)} filas)\")\n",
    "    else:\n",
    "        print(\"Aviso: no encuentro ninguna de las edades prioridad; continúo sin filtrar age.\")\n",
    "\n",
    "# WSTATUS: prioridad EMP > TOTAL; si nada de eso, agruparé promediando\n",
    "wstatus_pick = None\n",
    "if \"wstatus\" in df.columns:\n",
    "    uw = set(df[\"wstatus\"])\n",
    "    if \"EMP\" in uw:\n",
    "        wstatus_pick = \"EMP\"\n",
    "    elif \"TOTAL\" in uw:\n",
    "        wstatus_pick = \"TOTAL\"\n",
    "    if wstatus_pick is not None:\n",
    "        before = len(df)\n",
    "        df = df[df[\"wstatus\"] == wstatus_pick]\n",
    "        print(f\"Filtrado wstatus: escojo {wstatus_pick}  ({before} -> {len(df)} filas)\")\n",
    "    else:\n",
    "        print(\"Aviso: no hay EMP/TOTAL en wstatus; luego promediaré por wstatus (aprox.).\")\n",
    "\n",
    "# Frecuencia de teletrabajo: USU/SMT\n",
    "freqcat_keep = {\"USU\",\"SMT\"}\n",
    "if \"frequenc\" in df.columns:\n",
    "    before = len(df)\n",
    "    df = df[df[\"frequenc\"].isin(freqcat_keep)]\n",
    "    print(f\"Filtrado frequenc (USU/SMT): {before} -> {len(df)} filas\")\n",
    "else:\n",
    "    raise ValueError(\"No encuentro columna 'frequenc' con categorías USU/SMT.\")\n",
    "\n",
    "# --- Construcción de telework_any ---\n",
    "\n",
    "group_cols = [\"geo\",\"time\"]\n",
    "# Si no pudimos fijar wstatus (no había EMP/TOTAL), promediamos entre wstatus (aproximación)\n",
    "if \"wstatus\" in df.columns and wstatus_pick is None:\n",
    "    group_cols.append(\"wstatus\")\n",
    "\n",
    "wide = df.pivot_table(index=group_cols, columns=\"frequenc\", values=\"value\", aggfunc=\"mean\")\n",
    "for c in (\"USU\",\"SMT\"):\n",
    "    if c not in wide.columns:\n",
    "        wide[c] = 0.0\n",
    "\n",
    "wide[\"telework_any\"] = wide[\"USU\"].fillna(0) + wide[\"SMT\"].fillna(0)\n",
    "wide = wide.reset_index()\n",
    "\n",
    "# Si aún hay wstatus (porque promediamos), colapsa a país-año (media simple, aprox.)\n",
    "if \"wstatus\" in wide.columns and wstatus_pick is None:\n",
    "    before = len(wide)\n",
    "    wide = wide.groupby([\"geo\",\"time\"], as_index=False)[[\"USU\",\"SMT\",\"telework_any\"]].mean()\n",
    "    print(f\"Agrupado por wstatus (aprox.): {before} -> {len(wide)} filas\")\n",
    "\n",
    "wide = wide.sort_values([\"geo\",\"time\"]).reset_index(drop=True)\n",
    "\n",
    "# Guardar\n",
    "OUT.parent.mkdir(parents=True, exist_ok=True)\n",
    "wide.to_csv(OUT, index=False)\n",
    "print(\"Guardado:\", OUT)\n",
    "display(wide.head())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6ed6ff28-7348-4d0a-ac36-d253a7fcaab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: ..\\data\\processed\\lfso_21jsat01_2015_2024_clean.csv | filas: 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo</th>\n",
       "      <th>time</th>\n",
       "      <th>share_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.089542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BE</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.085934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BG</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.048013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CH</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.104222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CY</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.103489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  geo  time  share_high\n",
       "0  AT  2021    0.089542\n",
       "1  BE  2021    0.085934\n",
       "2  BG  2021    0.048013\n",
       "3  CH  2021    0.104222\n",
       "4  CY  2021    0.103489"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Años presentes: [2021]\n",
      "Países (muestra): ['AT', 'BE', 'BG', 'CH', 'CY', 'CZ', 'DE', 'DK', 'EA20', 'EE'] ...\n"
     ]
    }
   ],
   "source": [
    "#Limpieza lfso_21jsat04 (satisfacción × teletrabajo × flexibilidad) \n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "RAW = Path(\"../data/raw/lfso_21jsat01.csv\")   # o .tsv\n",
    "OUT = Path(\"../data/processed/lfso_21jsat01_2015_2024_clean.csv\")\n",
    "\n",
    "df0 = pd.read_csv(RAW)\n",
    "\n",
    "# Normaliza nombres clave\n",
    "df = df0.rename(columns={\"TIME_PERIOD\":\"time\", \"OBS_VALUE\":\"value\"}).copy()\n",
    "\n",
    "# Extrae año YYYY aunque venga como '2021-01'/'2021Q1'\n",
    "if \"time\" in df.columns:\n",
    "    df[\"time_year\"] = df[\"time\"].astype(str).str.extract(r\"(\\d{4})\")\n",
    "    df[\"time_year\"] = pd.to_numeric(df[\"time_year\"], errors=\"coerce\")\n",
    "    # nos quedamos con 2015..2024 si existen (si solo hay 2021, quedará 2021)\n",
    "    df = df[df[\"time_year\"].between(2015, 2024, inclusive=\"both\")]\n",
    "    df[\"time\"] = df[\"time_year\"].astype(\"Int64\")\n",
    "    df.drop(columns=[\"time_year\"], inplace=True)\n",
    "else:\n",
    "    raise ValueError(\"No encuentro columna temporal (TIME_PERIOD/time).\")\n",
    "\n",
    "# A numérico; NO filtramos por unit/freq para no vaciar\n",
    "df[\"value\"] = pd.to_numeric(df[\"value\"], errors=\"coerce\")\n",
    "\n",
    "# Quita NA y baja fiabilidad si quieres ser estricto\n",
    "df = df[df[\"value\"].notna()]\n",
    "if \"OBS_FLAG\" in df.columns:\n",
    "    df = df[~df[\"OBS_FLAG\"].fillna(\"\").str.contains(\"u\")]\n",
    "\n",
    "# Totales razonables de sexo/edad (si existen)\n",
    "if \"sex\" in df.columns:\n",
    "    df = df[df[\"sex\"].isin([\"T\",\"TOTAL\",\"All sexes\"]) | df[\"sex\"].isna()]\n",
    "if \"age\" in df.columns:\n",
    "    df = df[df[\"age\"].isin([\"Y20-64\",\"Y15-64\",\"Y15-74\",\"TOTAL\",\"All ages\"]) | df[\"age\"].isna()]\n",
    "\n",
    "# Algunos ficheros traen 'unit' = THS_PER (miles); otros 'PC' (porcentaje).\n",
    "# Para poder comparar países, construimos proporción dentro de cada grupo.\n",
    "# Grupo de referencia (incluye c_birth/isced11 si existen):\n",
    "group_keys = [\"geo\",\"time\"]\n",
    "for extra in [\"c_birth\",\"isced11\"]:\n",
    "    if extra in df.columns:\n",
    "        group_keys.append(extra)\n",
    "\n",
    "# Necesitamos 'lev_satis' (si no existe, no podemos construir HIGH):\n",
    "if \"lev_satis\" not in df.columns:\n",
    "    # fallback: usa 'value' promedio como proxy\n",
    "    dfm = df.groupby([\"geo\",\"time\"], as_index=False)[\"value\"].mean()\n",
    "    dfm = dfm.rename(columns={\"value\":\"share_high\"})\n",
    "else:\n",
    "    # Suma por grupo (para proporciones si unit=THS_PER) o normaliza si unit ya es PC\n",
    "    gsum = df.groupby(group_keys, as_index=False)[\"value\"].sum().rename(columns={\"value\":\"group_total\"})\n",
    "    dff = df.merge(gsum, on=group_keys, how=\"left\")\n",
    "\n",
    "    # Si 'unit' es PC, la suma de categorías suele ~100, si es THS_PER suma personas.\n",
    "    # Construimos share = value / group_total, pero si group_total ~0 o ~100,\n",
    "    # este cociente también sirve (quedará ~ value/100 si 'PC').\n",
    "    dff[\"share\"] = np.where(dff[\"group_total\"]>0, dff[\"value\"]/dff[\"group_total\"], np.nan)\n",
    "\n",
    "    # Nos quedamos con HIGH\n",
    "    df_high = dff[dff[\"lev_satis\"].astype(str).str.upper().eq(\"HIGH\")].copy()\n",
    "    dfm = df_high.groupby([\"geo\",\"time\"], as_index=False)[\"share\"].mean().rename(columns={\"share\":\"share_high\"})\n",
    "\n",
    "# Orden y guardado\n",
    "dfm = dfm.sort_values([\"geo\",\"time\"]).reset_index(drop=True)\n",
    "OUT.parent.mkdir(parents=True, exist_ok=True)\n",
    "dfm.to_csv(OUT, index=False)\n",
    "print(\"Guardado:\", OUT, \"| filas:\", len(dfm))\n",
    "display(dfm.head())\n",
    "\n",
    "# Diagnóstico útil:\n",
    "print(\"\\nAños presentes:\", sorted(dfm[\"time\"].unique()))\n",
    "print(\"Países (muestra):\", sorted(dfm[\"geo\"].unique())[:10], \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a4fd11-0505-4940-bb1d-6fe502fceaec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
